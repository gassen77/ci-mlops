name: CI Workflow

on:
  push:
    branches: ["main"]
  pull_request:
    branches: ["main"]
  workflow_dispatch:

permissions:
  contents: write
  packages: write

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      # Checkout code
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          lfs: true

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
         python-version: '3.8'

      - name: Cache Python dependencies
        uses: actions/cache@v2
        with:
         path: ~/.cache/pip
         key: ${{ runner.os }}-python-${{ hashFiles('**/requirements.txt') }}  # Modify this to change the cache key
         restore-keys: |
          ${{ runner.os }}-python-

      # Set up Docker
      - name: Set up Docker
        run: |
          sudo apt-get update
          sudo apt-get install -y apt-transport-https ca-certificates curl software-properties-common
          curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
          echo "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
          sudo apt-get update
          sudo apt-get install -y docker-ce docker-ce-cli containerd.io

      # Install Python dependencies for the ML project and linters
      - name: Install Packages
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          pip install black flake8 mlflow  # Install linters, formatters, and MLflow

      # Lint code using flake8 and allow errors without stopping the workflow
      - name: Lint code with flake8
        run: |
          flake8 . || true  # Lint all Python files, but don't stop the workflow if errors are found

      # Format code using black
      - name: Format code with black
        run: |
          black --check .  # Check if the code is formatted, will fail if not
        continue-on-error: true  # Allow the workflow to continue even if the check fails

      # Build Docker image
      - name: Build Docker image
        run: |
          docker build --no-cache -t ghcr.io/${{ github.repository }}/my-ml-image:latest .

      # Login to GitHub Container Registry
      - name: Login to GitHub Container Registry
        run: |
          echo ${{ secrets.GITHUB_TOKEN }} | docker login ghcr.io -u ${{ github.actor }} --password-stdin

      # Tag Docker image
      - name: Tag Docker image
        run: |
          docker tag ghcr.io/${{ github.repository }}/my-ml-image:latest ghcr.io/${{ github.repository }}/my-ml-image:latest

      # Push Docker image to GHCR
      - name: Push Docker image to GHCR
        run: |
          docker push ghcr.io/${{ github.repository }}/my-ml-image:latest

      # Run Docker container
      - name: Run Docker container
        run: |
          docker run --name ml-container -d ghcr.io/${{ github.repository }}/my-ml-image:latest

      # Check if the Docker container is running
      - name: Check Docker container status
        run: |
          docker ps -a
      # update dependencies inside Docker container
      - name: update depedencies
        run: |
            docker exec ml-container pip install --upgrade numpy
            docker exec ml-container pip install --upgrade --force-reinstall scikit-learn
            docker exec ml-container pip install --upgrade --force-reinstall skops
           

      # Test ML project inside Docker container
      - name: Test ML project in Docker container
        run: |
          
          docker exec ml-container python /app/train.py  # Or any other script you want to run that uses MLflow
           
      # Run the training script inside the Docker container
      - name: Run training script inside Docker container
        run: |
          docker exec ml-container python /app/train.py  # Adjust path as needed

      # Optional: Upload MLflow artifacts
      - name: Upload MLflow artifacts
        uses: actions/upload-artifact@v3
        with:
          name: mlflow-logs
          path: /app/mlruns  # Adjust path as needed, assuming MLflow logs are stored here

      # Cleanup Docker container
      - name: Cleanup Docker container
        run: |
          docker stop ml-container
          docker rm ml-container

      # Optional: Cleanup Docker image if you want to save space
      - name: Cleanup Docker image
        run: |
          docker rmi ghcr.io/${{ github.repository }}/my-ml-image:latest
